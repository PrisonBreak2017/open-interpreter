### OPEN INTERPRETER CONFIGURATION FILE

# Remove the "#" before the settings below to use them.

llm:
  model: "gpt-4-32k-0314"
  temperature: 0
  api_key: "sk-YdzPwOl5IXHWlq5AB1A4A26fEdA3471bBaE82483Dc0d1c1a"   # Your API key, if the API requires it
  api_base: "http://137.175.19.77:3000/v1"  # The URL where an OpenAI-compatible server is running to handle LLM API requests
  # api_version: ...  # The version of the API (this is primarily for Azure)
  # max_output: 2500  # The maximum characters of code output visible to the LLM

# custom_instructions: ""  # This will be appended to the system message
auto_run: True  # If True, code will run without asking for confirmation
# safe_mode: "off"  # The safety mode for the LLM â€” one of "off", "ask", "auto"
# offline: False  # If True, will disable some online features like checking for updates
verbose: True  # If True, will print detailed logs

# All options: https://docs.openinterpreter.com/settings

version: 0.2.0 # Configuration file version (do not modify)
